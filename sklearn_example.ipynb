{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### document classification example\n",
    "based on sklearn site example entitled \"Classification of text documents using sparse features\"\n",
    "https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html\n",
    "\n",
    " - some of the code appears to be out of date (e.g. old string formatting syntax)\n",
    " - much of it is also geared toward CLI runs - adapting it as a notebook\n",
    " \n",
    " The BSD 3-clause license allows you almost unlimited freedom with the software so long as you include the BSD copyright and license notice in it.\n",
    "\n",
    "Â© 2007 - 2021, scikit-learn developers (BSD License). \n",
    "\n",
    "Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n",
    "1.     Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n",
    "1.     Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. \n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'print_report': True,\n",
       " 'select_chi2': 1500,\n",
       " 'print_cm': True,\n",
       " 'print_top10': True,\n",
       " 'all_categories': True,\n",
       " 'use_hashing': True,\n",
       " 'n_features': 65536,\n",
       " 'filtered': True}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Mathieu Blondel <mathieu@mblondel.org>\n",
    "#         Lars Buitinck\n",
    "# License: BSD 3 clause\n",
    "# modified: Robert Sunderland - 2021\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#changed from CLI options to inline\n",
    "\n",
    "optdict = {'print_report': True,# Print a detailed classification report.\n",
    " 'select_chi2': 1500,#Select some number of features using a chi-squared test\n",
    " 'print_cm': True,#Print the confusion matrix.\n",
    " 'print_top10': True, #Print ten most discriminative terms per class for every classifier\n",
    " 'all_categories': True, #Whether to use all categories or not\n",
    " 'use_hashing': True, #Use a hashing vectorizer\n",
    " 'n_features': 2**16, #n_features when using the hashing vectorizer\n",
    " 'filtered': True} #Remove newsgroup information that is easily overfit: headers, signatures, and quoting\n",
    "\n",
    "\n",
    "optdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'print_report': True,\n",
       " 'select_chi2': 1500,\n",
       " 'print_cm': True,\n",
       " 'print_top10': True,\n",
       " 'all_categories': True,\n",
       " 'use_hashing': True,\n",
       " 'n_features': 65536,\n",
       " 'filtered': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "#d = {'key1': 'value1', 'key2': 'value2'}\n",
    "opts = SimpleNamespace(**optdict)\n",
    "#opts.__dict__\n",
    "vars(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'print_report': True,\n",
       " 'select_chi2': 1500,\n",
       " 'print_cm': True,\n",
       " 'print_top10': True,\n",
       " 'all_categories': True,\n",
       " 'use_hashing': True,\n",
       " 'n_features': 65536,\n",
       " 'filtered': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alternative solution\n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n",
    "        \n",
    "opts = objectview(optdict)\n",
    "#opts.__dict__\n",
    "vars(opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.all_categories = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 newsgroups dataset for categories:['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n"
     ]
    }
   ],
   "source": [
    "## load data\n",
    "if opts.all_categories:\n",
    "    categories = None\n",
    "else:\n",
    "    categories = [\n",
    "        \"alt.atheism\",\n",
    "        \"talk.religion.misc\",\n",
    "        \"comp.graphics\",\n",
    "        \"sci.space\",\n",
    "    ]\n",
    "print(f\"20 newsgroups dataset for categories:{categories if categories else 'all'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('headers', 'footers', 'quotes')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if opts.filtered:\n",
    "    remove = (\"headers\", \"footers\", \"quotes\")\n",
    "else:\n",
    "    remove = ()\n",
    "    \n",
    "remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "data_train = fetch_20newsgroups(subset=\"train\", categories=categories, shuffle=True, random_state=42, remove=remove)\n",
    "\n",
    "data_test = fetch_20newsgroups(subset=\"test\", categories=categories, shuffle=True, random_state=42, remove=remove)\n",
    "print(\"data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sklearn.utils.Bunch, sklearn.utils.Bunch)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_train), type(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# order of labels in `target_names` can be different from `categories`\n",
    "target_names = data_train.target_names\n",
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2034 documents - 2.43MB (training set)\n",
      "1353 documents - 1.8MB (test set)\n",
      "4 categories\n"
     ]
    }
   ],
   "source": [
    "def size_mb(docs):\n",
    "    return sum(len(s.encode(\"utf-8\")) for s in docs) / 1e6\n",
    "\n",
    "\n",
    "data_train_size_mb = size_mb(data_train.data)\n",
    "data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "print(f\"{len(data_train.data)} documents - {data_train_size_mb:0.3}MB (training set)\")\n",
    "print(f\"{len(data_test.data)} documents - {data_test_size_mb:0.3}MB (test set)\")\n",
    "print(f\"{len(target_names)} categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, 2034, numpy.ndarray, 1353)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split a training set and a test set\n",
    "y_train, y_test = data_train.target, data_test.target\n",
    "type(y_train), len(y_train), type(y_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.use_hashing = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the training data using a sparse vectorizer\n",
      "done in 0.28651s at 8.47 MB/s\n",
      "n_samples: 2034, n_features: 26576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "if opts.use_hashing:\n",
    "    vectorizer = HashingVectorizer(stop_words=\"english\", alternate_sign=False, n_features=opts.n_features)\n",
    "    X_train = vectorizer.transform(data_train.data)\n",
    "else:\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words=\"english\")\n",
    "    X_train = vectorizer.fit_transform(data_train.data)\n",
    "duration = time() - t0\n",
    "print(f\"done in {duration:0.5}s at {data_train_size_mb / duration:0.3} MB/s\" )\n",
    "print(f\"n_samples: {X_train.shape[0]}, n_features: {X_train.shape[1]}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '00000',\n",
       " '000000',\n",
       " '000005102000',\n",
       " '000062david42',\n",
       " '0001',\n",
       " '000100255pixel',\n",
       " '00041032',\n",
       " '0004136',\n",
       " '0004246',\n",
       " '0004422',\n",
       " '00044513',\n",
       " '0004847546',\n",
       " '0005',\n",
       " '0007',\n",
       " '00090711',\n",
       " '000usd',\n",
       " '0012',\n",
       " '001200201pixel',\n",
       " '0018',\n",
       " '00196',\n",
       " '0020',\n",
       " '0022',\n",
       " '0028',\n",
       " '0029',\n",
       " '0033',\n",
       " '0034',\n",
       " '0038',\n",
       " '0049',\n",
       " '006',\n",
       " '0065',\n",
       " '0094',\n",
       " '0098',\n",
       " '00index',\n",
       " '00pm',\n",
       " '01',\n",
       " '0100',\n",
       " '013846',\n",
       " '01752',\n",
       " '0179',\n",
       " '01821',\n",
       " '01826',\n",
       " '0184',\n",
       " '01852',\n",
       " '01854',\n",
       " '01890',\n",
       " '018b',\n",
       " '0195',\n",
       " '0199',\n",
       " '01a',\n",
       " '02',\n",
       " '020',\n",
       " '0200',\n",
       " '020359',\n",
       " '020637',\n",
       " '02115',\n",
       " '02138',\n",
       " '02139',\n",
       " '02154',\n",
       " '02178',\n",
       " '0223',\n",
       " '0235',\n",
       " '023b',\n",
       " '0245',\n",
       " '03',\n",
       " '030',\n",
       " '0300',\n",
       " '03051',\n",
       " '0330',\n",
       " '034',\n",
       " '034101',\n",
       " '04',\n",
       " '040',\n",
       " '040286',\n",
       " '0410',\n",
       " '04110',\n",
       " '041493003715',\n",
       " '0418',\n",
       " '045',\n",
       " '04g',\n",
       " '05',\n",
       " '050',\n",
       " '0500',\n",
       " '050524',\n",
       " '0511',\n",
       " '05402',\n",
       " '05446',\n",
       " '0545',\n",
       " '054589e',\n",
       " '058',\n",
       " '06',\n",
       " '060',\n",
       " '0605',\n",
       " '06111',\n",
       " '06179397',\n",
       " '06487',\n",
       " '0649',\n",
       " '067',\n",
       " '0674',\n",
       " '068',\n",
       " '0695',\n",
       " '07',\n",
       " '070',\n",
       " '071',\n",
       " '0729',\n",
       " '0739',\n",
       " '074',\n",
       " '07410',\n",
       " '07653',\n",
       " '077',\n",
       " '08',\n",
       " '08080',\n",
       " '0820',\n",
       " '08540',\n",
       " '08544',\n",
       " '0856e16',\n",
       " '0865',\n",
       " '08786',\n",
       " '08934',\n",
       " '09',\n",
       " '0900',\n",
       " '0901',\n",
       " '0903',\n",
       " '0908',\n",
       " '0926',\n",
       " '0941',\n",
       " '0943',\n",
       " '0970',\n",
       " '0971',\n",
       " '0988',\n",
       " '0_',\n",
       " '0a',\n",
       " '0b',\n",
       " '0e9',\n",
       " '0km',\n",
       " '0mph',\n",
       " '0w',\n",
       " '0x',\n",
       " '0x00',\n",
       " '0x100',\n",
       " '0x1f',\n",
       " '0x3d4',\n",
       " '0xc010',\n",
       " '0xc018',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10000',\n",
       " '100000',\n",
       " '1000r',\n",
       " '1001',\n",
       " '10012',\n",
       " '10019',\n",
       " '10020',\n",
       " '10022',\n",
       " '10023',\n",
       " '1003',\n",
       " '10036',\n",
       " '10038',\n",
       " '100c',\n",
       " '100k',\n",
       " '100km',\n",
       " '100megs',\n",
       " '100nm',\n",
       " '100th',\n",
       " '101',\n",
       " '1010',\n",
       " '101010',\n",
       " '10158',\n",
       " '10179',\n",
       " '101h',\n",
       " '102',\n",
       " '1024',\n",
       " '1024x1024',\n",
       " '1024x512',\n",
       " '1024x728',\n",
       " '1024x768',\n",
       " '1024x768x24',\n",
       " '1024x768x65000',\n",
       " '1024x786x24',\n",
       " '10281',\n",
       " '103',\n",
       " '1030',\n",
       " '1039',\n",
       " '104',\n",
       " '1044',\n",
       " '10460',\n",
       " '1049',\n",
       " '105',\n",
       " '105366',\n",
       " '1059',\n",
       " '105m',\n",
       " '106',\n",
       " '1060',\n",
       " '1066',\n",
       " '107',\n",
       " '1070',\n",
       " '1079',\n",
       " '108',\n",
       " '1080',\n",
       " '1084',\n",
       " '109',\n",
       " '109125',\n",
       " '109147',\n",
       " '10_',\n",
       " '10bps',\n",
       " '10cm',\n",
       " '10fps',\n",
       " '10h',\n",
       " '10k',\n",
       " '10km',\n",
       " '10kw',\n",
       " '10m',\n",
       " '10mhz',\n",
       " '11',\n",
       " '110',\n",
       " '1100',\n",
       " '110m',\n",
       " '110mbytes',\n",
       " '111',\n",
       " '1113',\n",
       " '111s',\n",
       " '112',\n",
       " '113',\n",
       " '1137',\n",
       " '114',\n",
       " '1145040',\n",
       " '115',\n",
       " '1150',\n",
       " '1151',\n",
       " '115m',\n",
       " '1163',\n",
       " '117',\n",
       " '1179',\n",
       " '118',\n",
       " '11838',\n",
       " '11888',\n",
       " '119',\n",
       " '1190',\n",
       " '1194',\n",
       " '1198',\n",
       " '119th',\n",
       " '11dec89',\n",
       " '11x17',\n",
       " '12',\n",
       " '120',\n",
       " '1200',\n",
       " '1200mi',\n",
       " '1200x900',\n",
       " '1201',\n",
       " '1204',\n",
       " '1207',\n",
       " '121',\n",
       " '1212',\n",
       " '121624',\n",
       " '122',\n",
       " '1220',\n",
       " '1222',\n",
       " '122356',\n",
       " '122nd',\n",
       " '123',\n",
       " '1234',\n",
       " '1238',\n",
       " '1244',\n",
       " '125',\n",
       " '1251',\n",
       " '125750',\n",
       " '12602',\n",
       " '12607',\n",
       " '12649',\n",
       " '1266',\n",
       " '127',\n",
       " '1271',\n",
       " '12770',\n",
       " '128',\n",
       " '1281',\n",
       " '128m',\n",
       " '129',\n",
       " '1290',\n",
       " '1292',\n",
       " '12km',\n",
       " '12m',\n",
       " '13',\n",
       " '130',\n",
       " '1300',\n",
       " '131',\n",
       " '1317',\n",
       " '132',\n",
       " '13255',\n",
       " '133',\n",
       " '1333',\n",
       " '133866082767180880e',\n",
       " '133941270127999174e',\n",
       " '134',\n",
       " '1342',\n",
       " '1343',\n",
       " '135',\n",
       " '1350',\n",
       " '1358',\n",
       " '135x180',\n",
       " '136',\n",
       " '13676',\n",
       " '137',\n",
       " '1370',\n",
       " '1372',\n",
       " '1374',\n",
       " '138',\n",
       " '1387',\n",
       " '138p',\n",
       " '139',\n",
       " '1395',\n",
       " '13e19',\n",
       " '13h',\n",
       " '14',\n",
       " '140',\n",
       " '1400',\n",
       " '14000',\n",
       " '1401',\n",
       " '140195',\n",
       " '140m',\n",
       " '141',\n",
       " '141592654',\n",
       " '1418',\n",
       " '142',\n",
       " '1420',\n",
       " '14215',\n",
       " '14226',\n",
       " '14228',\n",
       " '1426',\n",
       " '143',\n",
       " '1436',\n",
       " '144',\n",
       " '14400',\n",
       " '1441',\n",
       " '145',\n",
       " '1452',\n",
       " '1453',\n",
       " '145mm',\n",
       " '146',\n",
       " '147',\n",
       " '148',\n",
       " '14801',\n",
       " '14853',\n",
       " '1487',\n",
       " '1489',\n",
       " '149',\n",
       " '1493',\n",
       " '14m',\n",
       " '14th',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '1500kg',\n",
       " '1500s',\n",
       " '1506',\n",
       " '1507',\n",
       " '150a',\n",
       " '150miles',\n",
       " '151',\n",
       " '1517',\n",
       " '151899',\n",
       " '151914',\n",
       " '152',\n",
       " '1520',\n",
       " '152528',\n",
       " '1528',\n",
       " '153',\n",
       " '1535',\n",
       " '153847166458030088e',\n",
       " '154',\n",
       " '1541',\n",
       " '1545',\n",
       " '154m',\n",
       " '155',\n",
       " '1550',\n",
       " '155622',\n",
       " '156',\n",
       " '1568',\n",
       " '157',\n",
       " '158',\n",
       " '1585',\n",
       " '159',\n",
       " '15bit',\n",
       " '15e10',\n",
       " '15m',\n",
       " '15mhz',\n",
       " '15rpm',\n",
       " '15th',\n",
       " '16',\n",
       " '160',\n",
       " '1600',\n",
       " '1607',\n",
       " '160x2xx',\n",
       " '161',\n",
       " '1618',\n",
       " '162',\n",
       " '1621',\n",
       " '1625',\n",
       " '1627',\n",
       " '1629',\n",
       " '163',\n",
       " '163729',\n",
       " '164',\n",
       " '1643',\n",
       " '165',\n",
       " '1660',\n",
       " '1663',\n",
       " '1666',\n",
       " '167',\n",
       " '167290000000000000e',\n",
       " '1673',\n",
       " '167317532658774153e',\n",
       " '168',\n",
       " '1680',\n",
       " '169',\n",
       " '1690',\n",
       " '1695',\n",
       " '16bit',\n",
       " '16m',\n",
       " '16th',\n",
       " '17',\n",
       " '170',\n",
       " '1700',\n",
       " '1704',\n",
       " '171',\n",
       " '171194',\n",
       " '1712',\n",
       " '1717',\n",
       " '172',\n",
       " '1728',\n",
       " '173',\n",
       " '1733',\n",
       " '1738',\n",
       " '174',\n",
       " '1741',\n",
       " '1744',\n",
       " '1747',\n",
       " '1749',\n",
       " '1753696',\n",
       " '1755',\n",
       " '176',\n",
       " '1765',\n",
       " '17654',\n",
       " '177',\n",
       " '1770',\n",
       " '1776',\n",
       " '178',\n",
       " '1780',\n",
       " '1785',\n",
       " '1788',\n",
       " '179',\n",
       " '1797',\n",
       " '17____',\n",
       " '17apr199316423628',\n",
       " '17f',\n",
       " '17th',\n",
       " '18',\n",
       " '180',\n",
       " '1800',\n",
       " '1800s',\n",
       " '1802',\n",
       " '1803',\n",
       " '1804',\n",
       " '1806',\n",
       " '18084tm',\n",
       " '181',\n",
       " '1813',\n",
       " '1815',\n",
       " '182',\n",
       " '1820',\n",
       " '18227',\n",
       " '183',\n",
       " '1830',\n",
       " '1838',\n",
       " '184',\n",
       " '184369999999999994e',\n",
       " '184377521828175002e',\n",
       " '1845',\n",
       " '185',\n",
       " '1850',\n",
       " '1855',\n",
       " '1857',\n",
       " '18583',\n",
       " '18590',\n",
       " '186',\n",
       " '1865',\n",
       " '187',\n",
       " '1870',\n",
       " '1876',\n",
       " '1881',\n",
       " '1883',\n",
       " '1885',\n",
       " '1888',\n",
       " '189',\n",
       " '1890',\n",
       " '1895',\n",
       " '18th',\n",
       " '19',\n",
       " '190',\n",
       " '1900',\n",
       " '1902',\n",
       " '1905',\n",
       " '1906',\n",
       " '1909',\n",
       " '1910',\n",
       " '1912',\n",
       " '191344498719999910e',\n",
       " '1915',\n",
       " '1919',\n",
       " '192',\n",
       " '1920',\n",
       " '192026707383028306e',\n",
       " '1921',\n",
       " '1922',\n",
       " '1925',\n",
       " '1926',\n",
       " '1927',\n",
       " '193',\n",
       " '1930s',\n",
       " '1931',\n",
       " '1933',\n",
       " '1935',\n",
       " '1937',\n",
       " '1938',\n",
       " '1939',\n",
       " '194',\n",
       " '1941',\n",
       " '1945',\n",
       " '1947',\n",
       " '1949',\n",
       " '195',\n",
       " '1950',\n",
       " '1956',\n",
       " '1957',\n",
       " '1958',\n",
       " '1959',\n",
       " '196',\n",
       " '1960',\n",
       " '1960s',\n",
       " '1961',\n",
       " '1962',\n",
       " '1963',\n",
       " '1964',\n",
       " '1965',\n",
       " '1966',\n",
       " '1967',\n",
       " '1968',\n",
       " '1969',\n",
       " '197',\n",
       " '1970',\n",
       " '1970s',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1974',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1977vii',\n",
       " '1978',\n",
       " '1979',\n",
       " '198',\n",
       " '1980',\n",
       " '1980s',\n",
       " '1981',\n",
       " '1982',\n",
       " '1983',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '199',\n",
       " '1990',\n",
       " '19907',\n",
       " '1990s',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1993apr13',\n",
       " '1993apr16',\n",
       " '1993apr18',\n",
       " '1993apr19',\n",
       " '1993apr21',\n",
       " '1993apr5',\n",
       " '1993apr9',\n",
       " '1993e',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1999',\n",
       " '19apr199320262420',\n",
       " '19b2',\n",
       " '19th',\n",
       " '1_',\n",
       " '1a',\n",
       " '1b',\n",
       " '1billion',\n",
       " '1bit',\n",
       " '1c',\n",
       " '1c8',\n",
       " '1cm',\n",
       " '1d',\n",
       " '1e',\n",
       " '1e16',\n",
       " '1e23',\n",
       " '1f',\n",
       " '1ff',\n",
       " '1g',\n",
       " '1m',\n",
       " '1mb',\n",
       " '1meg',\n",
       " '1mil',\n",
       " '1mm',\n",
       " '1n4',\n",
       " '1qi83b',\n",
       " '1qjahh',\n",
       " '1qp',\n",
       " '1qvabj',\n",
       " '1s7',\n",
       " '1st',\n",
       " '1sz',\n",
       " '1x',\n",
       " '1x1',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '20000',\n",
       " '20001',\n",
       " '20003',\n",
       " '20004',\n",
       " '20006',\n",
       " '2000ad',\n",
       " '2001',\n",
       " '200114',\n",
       " '20013',\n",
       " '2002',\n",
       " '20024',\n",
       " '2003',\n",
       " '20036',\n",
       " '20037',\n",
       " '2004',\n",
       " '20044',\n",
       " '200447',\n",
       " '2005',\n",
       " '20054',\n",
       " '2006',\n",
       " '20071',\n",
       " '20073',\n",
       " '20077',\n",
       " '20084',\n",
       " '2009',\n",
       " '200k',\n",
       " '200m',\n",
       " '200mph',\n",
       " '201',\n",
       " '2010',\n",
       " '2016',\n",
       " '2017760',\n",
       " '202',\n",
       " '2020',\n",
       " '2023',\n",
       " '2025',\n",
       " '2029',\n",
       " '203',\n",
       " '2030',\n",
       " '20402',\n",
       " '2042',\n",
       " '2048x1024',\n",
       " '2049',\n",
       " '205',\n",
       " '20546',\n",
       " '206',\n",
       " '206264',\n",
       " '206265',\n",
       " '20771',\n",
       " '208',\n",
       " '20854',\n",
       " '208mm',\n",
       " '209',\n",
       " '20apr199312262902',\n",
       " '20hz',\n",
       " '20k',\n",
       " '20khz',\n",
       " '20m',\n",
       " '20mbytes',\n",
       " '20mhz',\n",
       " '20th',\n",
       " '21',\n",
       " '210',\n",
       " '2100',\n",
       " '21000',\n",
       " '21001',\n",
       " '2102',\n",
       " '2108',\n",
       " '211',\n",
       " '2110',\n",
       " '2112',\n",
       " '211216',\n",
       " '2113',\n",
       " '212',\n",
       " '21211',\n",
       " '21228',\n",
       " '21240',\n",
       " '213',\n",
       " '214',\n",
       " '2140',\n",
       " '215',\n",
       " '2150',\n",
       " '216',\n",
       " '217',\n",
       " '2172',\n",
       " '2175',\n",
       " '2178',\n",
       " '218',\n",
       " '21934',\n",
       " '2197',\n",
       " '21st',\n",
       " '22',\n",
       " '220',\n",
       " '2200',\n",
       " '22091',\n",
       " '22092',\n",
       " '221',\n",
       " '22110',\n",
       " '2215',\n",
       " '22152',\n",
       " '22159',\n",
       " '22180',\n",
       " '2219',\n",
       " '222',\n",
       " '22202',\n",
       " '2222',\n",
       " '22229',\n",
       " '2227',\n",
       " '223',\n",
       " '22304',\n",
       " '2238',\n",
       " '2239',\n",
       " '224',\n",
       " '225',\n",
       " '226',\n",
       " '22621',\n",
       " '22621u',\n",
       " '22623',\n",
       " '22623u',\n",
       " '2268',\n",
       " '227',\n",
       " '2272',\n",
       " '227m',\n",
       " '228',\n",
       " '22800',\n",
       " '229',\n",
       " '2290',\n",
       " '22m',\n",
       " '22nd',\n",
       " '23',\n",
       " '230',\n",
       " '2300',\n",
       " '230236',\n",
       " '23089',\n",
       " '231',\n",
       " '231733isscck',\n",
       " '232',\n",
       " '23235',\n",
       " '233',\n",
       " '23337',\n",
       " '2341',\n",
       " '236',\n",
       " '23665',\n",
       " '237',\n",
       " '238',\n",
       " '239',\n",
       " '2393',\n",
       " '2396',\n",
       " '23h08m47s',\n",
       " '24',\n",
       " '240',\n",
       " '2400',\n",
       " '24000',\n",
       " '2400bd',\n",
       " '2400bps',\n",
       " '240438',\n",
       " '241',\n",
       " '241113',\n",
       " '242',\n",
       " '2425',\n",
       " '243',\n",
       " '2448',\n",
       " '245',\n",
       " '2452',\n",
       " '2455',\n",
       " '2458',\n",
       " '246',\n",
       " '2460',\n",
       " '2468',\n",
       " '2475',\n",
       " '2476v',\n",
       " '248',\n",
       " '248m',\n",
       " '249',\n",
       " '2490747',\n",
       " '2492930',\n",
       " '2493',\n",
       " '2494',\n",
       " '2496',\n",
       " '24bit',\n",
       " '24bits',\n",
       " '24s',\n",
       " '24th',\n",
       " '24x',\n",
       " '25',\n",
       " '250',\n",
       " '2500',\n",
       " '2509',\n",
       " '250k',\n",
       " '2513',\n",
       " '25192',\n",
       " '252',\n",
       " '2520',\n",
       " '25286',\n",
       " '253',\n",
       " '2539',\n",
       " '254',\n",
       " '255',\n",
       " '25599',\n",
       " '256',\n",
       " '256x256',\n",
       " '257',\n",
       " '258',\n",
       " '2587',\n",
       " '25aircraft',\n",
       " '25billion',\n",
       " '25k',\n",
       " '25mhz',\n",
       " '25th',\n",
       " '25x',\n",
       " '26',\n",
       " '260',\n",
       " '2600',\n",
       " '2601',\n",
       " '261',\n",
       " '2616',\n",
       " '261757',\n",
       " '2624',\n",
       " '2626',\n",
       " '263',\n",
       " '2633',\n",
       " '264',\n",
       " '264190',\n",
       " '26465',\n",
       " '265',\n",
       " '2651',\n",
       " '267',\n",
       " '26996',\n",
       " '26m',\n",
       " '27',\n",
       " '270',\n",
       " '272',\n",
       " '2727',\n",
       " '273',\n",
       " '27300',\n",
       " '274',\n",
       " '2748',\n",
       " '275',\n",
       " '27517',\n",
       " '276',\n",
       " '277',\n",
       " '27706',\n",
       " '2780',\n",
       " '279',\n",
       " '27th',\n",
       " '28',\n",
       " '280',\n",
       " '2800',\n",
       " '2801',\n",
       " '281',\n",
       " '2812',\n",
       " '28130',\n",
       " '28174',\n",
       " '282',\n",
       " '2824',\n",
       " '28254',\n",
       " '2830',\n",
       " '284',\n",
       " '285',\n",
       " '2850',\n",
       " '286',\n",
       " '286160',\n",
       " '286165',\n",
       " '2864',\n",
       " '2867',\n",
       " '287',\n",
       " '2870',\n",
       " '288',\n",
       " '2888',\n",
       " '289',\n",
       " '28th',\n",
       " '29',\n",
       " '290',\n",
       " '2900',\n",
       " '29077',\n",
       " '2908404',\n",
       " '291',\n",
       " '2912',\n",
       " '293',\n",
       " '2935',\n",
       " '294',\n",
       " '29405',\n",
       " '295',\n",
       " '296',\n",
       " '2973',\n",
       " '298',\n",
       " '2980',\n",
       " '29887',\n",
       " '2989',\n",
       " '299',\n",
       " '299792',\n",
       " '299792458',\n",
       " '29th',\n",
       " '2_c',\n",
       " '2a',\n",
       " '2ad',\n",
       " '2ax',\n",
       " '2by',\n",
       " '2c',\n",
       " '2cz',\n",
       " '2d',\n",
       " '2e',\n",
       " '2e15',\n",
       " '2e27',\n",
       " '2e3',\n",
       " '2e30',\n",
       " '2e5',\n",
       " '2etc',\n",
       " '2gm',\n",
       " '2mb',\n",
       " '2metres',\n",
       " '2nd',\n",
       " '2pe',\n",
       " '2rcirc',\n",
       " '2s2d',\n",
       " '2x',\n",
       " '2y3',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '30000',\n",
       " '3001',\n",
       " '3005',\n",
       " '300bps',\n",
       " '300nm',\n",
       " '301',\n",
       " '302',\n",
       " '303',\n",
       " '30329',\n",
       " '30347',\n",
       " '30348',\n",
       " '3039',\n",
       " '304',\n",
       " '304pp____________',\n",
       " '305',\n",
       " '3059',\n",
       " '3075',\n",
       " '309',\n",
       " '3098',\n",
       " '30cm',\n",
       " '30fps',\n",
       " '30th',\n",
       " '31',\n",
       " '310',\n",
       " '3100',\n",
       " '3113',\n",
       " '312',\n",
       " '3123',\n",
       " '313',\n",
       " '3136',\n",
       " '314',\n",
       " '3141',\n",
       " '315',\n",
       " '31500',\n",
       " '31556925',\n",
       " '3159',\n",
       " '316',\n",
       " '3184',\n",
       " '3185',\n",
       " '3193',\n",
       " '3197',\n",
       " '31mar199321091163',\n",
       " '32',\n",
       " '320',\n",
       " '3206',\n",
       " '320x200',\n",
       " '320x200x256',\n",
       " '320x240',\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = vectorizer.get_feature_names()#Array mapping from feature integer indices to feature name.\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(vectorizer.vocabulary_)#same as get_feature_names\n",
    "vectorizer.vocabulary_['001200201pixel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the test data using the same vectorizer\n",
      "done in 0.18052s at 9.97 MB/s\n",
      "n_samples: 1353, n_features: 26576\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting features from the test data using the same vectorizer\")\n",
    "t0 = time()\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "duration = time() - t0\n",
    "#print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
    "#print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print(f\"done in {duration:0.5}s at {data_test_size_mb / duration:0.3} MB/s\" )\n",
    "print(f\"n_samples: {X_test.shape[0]}, n_features: {X_test.shape[1]}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            00\n",
       "1           000\n",
       "2          0000\n",
       "3         00000\n",
       "4        000000\n",
       "          ...  \n",
       "26571      zwak\n",
       "26572    zwakke\n",
       "26573     zware\n",
       "26574    zwarte\n",
       "26575     zyxel\n",
       "Length: 26576, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mapping from integer feature name to original token string\n",
    "if opts.use_hashing:\n",
    "    feature_names = None\n",
    "else:\n",
    "    #feature_names = vectorizer.get_feature_names_out()#not in v0.23.2\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "pd.Series(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 1500 best features by a chi-squared test\n",
      "done in 0.025320768356323242s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['00', '10', '1024x768', ..., 'yo', 'zeus', 'zip'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "if opts.select_chi2:\n",
    "    print(\"Extracting %d best features by a chi-squared test\" % opts.select_chi2)\n",
    "    t0 = time()\n",
    "    ch2 = SelectKBest(chi2, k=opts.select_chi2)\n",
    "    X_train = ch2.fit_transform(X_train, y_train)\n",
    "    X_test = ch2.transform(X_test)\n",
    "    if feature_names is not None:\n",
    "        # keep selected feature names\n",
    "        #feature_names = feature_names[ch2.get_support()] #fails - filtering a list with a boolean?\n",
    "        feature_names = pd.Series(feature_names)[ch2.get_support()].values\n",
    "\n",
    "    print(f\"done in {(time() - t0)}s\" )\n",
    "\n",
    "feature_names\n",
    "#def trim(s):\n",
    "#    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "#    return s if len(s) <= 80 else s[:77] + \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# benchmark classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#benchmark classifiers - utility function\n",
    "from sklearn import metrics\n",
    "from sklearn.utils.extmath import density\n",
    "def benchmark(clf, prettyname=None, apptext = ''):\n",
    "    \"\"\" utiltiy function for determining how good the classifier is \n",
    "    doesn't return the output from the classifier\"\"\"\n",
    "    print(\"_\" * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(f\"train time: {train_time}fs\" )\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(f\"test time:  {test_time}fs\" )\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(f\"accuracy:   {score}f\" )\n",
    "\n",
    "    if hasattr(clf, \"coef_\"):\n",
    "        print(f\"dimensionality: {clf.coef_.shape[1]}\" )\n",
    "        print(f\"density: {density(clf.coef_)}\"  )\n",
    "\n",
    "        if opts.print_top10 and feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, label in enumerate(target_names):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(f\"{label}: {' '.join(feature_names[top10])}\".strip() )\n",
    "        print()\n",
    "\n",
    "    if opts.print_report:\n",
    "        print(\"classification report:\")\n",
    "        print(metrics.classification_report(y_test, pred, target_names=target_names))\n",
    "\n",
    "    if opts.print_cm:\n",
    "        print(\"confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split(\"(\")[0] if not prettyname else prettyname\n",
    "    if len(apptext)>0: \n",
    "        clf_descr += f\" {apptext}\"\n",
    "    \n",
    "    return clf_descr, score, train_time, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(solver='sag', tol=0.01)\n",
      "train time: 0.033907175064086914fs\n",
      "test time:  0.0fs\n",
      "accuracy:   0.7605321507760532f\n",
      "dimensionality: 1500\n",
      "density: 1.0\n",
      "top 10 keywords per class:\n",
      "alt.atheism: cruel deletion islamic atheist islam bobby motto atheists atheism religion\n",
      "comp.graphics: images pov card 42 hi image file 3d computer graphics\n",
      "sci.space: air sci moon flight shuttle spacecraft launch nasa orbit space\n",
      "talk.religion.misc: order abortion koresh rosicrucian christ children jesus fbi christians christian\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.71      0.58      0.64       319\n",
      "     comp.graphics       0.87      0.89      0.88       389\n",
      "         sci.space       0.73      0.92      0.81       394\n",
      "talk.religion.misc       0.68      0.53      0.60       251\n",
      "\n",
      "          accuracy                           0.76      1353\n",
      "         macro avg       0.75      0.73      0.73      1353\n",
      "      weighted avg       0.76      0.76      0.75      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[185  14  59  61]\n",
      " [  5 348  35   1]\n",
      " [ 11  20 362   1]\n",
      " [ 61  16  40 134]]\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(max_iter=50)\n",
      "train time: 0.010387182235717773fs\n",
      "test time:  0.0fs\n",
      "accuracy:   0.7191426459719142f\n",
      "dimensionality: 1500\n",
      "density: 0.7231666666666666\n",
      "top 10 keywords per class:\n",
      "alt.atheism: risk natural agreed believing falls imaginative enlightening atheist contradictory deletion\n",
      "comp.graphics: daemon 3d 42 pov printing keywords chip 3do ditto graphics\n",
      "sci.space: _perijoves_ launch solar wuarchive sherzer dc methodology orbit nasa space\n",
      "talk.religion.misc: deity frank predicts critus lunacy decenso themes actions shirts cult\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.64      0.61      0.62       319\n",
      "     comp.graphics       0.78      0.87      0.83       389\n",
      "         sci.space       0.80      0.76      0.78       394\n",
      "talk.religion.misc       0.57      0.55      0.56       251\n",
      "\n",
      "          accuracy                           0.72      1353\n",
      "         macro avg       0.70      0.70      0.70      1353\n",
      "      weighted avg       0.72      0.72      0.72      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[194  24  25  76]\n",
      " [ 11 339  31   8]\n",
      " [ 28  45 301  20]\n",
      " [ 70  24  18 139]]\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(max_iter=50)\n",
      "train time: 0.01795172691345215fs\n",
      "test time:  0.000997781753540039fs\n",
      "accuracy:   0.7354028085735402f\n",
      "dimensionality: 1500\n",
      "density: 0.9683333333333334\n",
      "top 10 keywords per class:\n",
      "alt.atheism: maddi illinois bobby offensive risk posters alternative believing atheism atheist\n",
      "comp.graphics: cch hi bitmap edges library pov 42 3d computer graphics\n",
      "sci.space: ross star launch shuttle jupiter 23 dc air orbit space\n",
      "talk.religion.misc: violation fellowship burned christians faith frank authority actions predicts cult\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.67      0.59      0.63       319\n",
      "     comp.graphics       0.87      0.85      0.86       389\n",
      "         sci.space       0.73      0.87      0.79       394\n",
      "talk.religion.misc       0.60      0.53      0.57       251\n",
      "\n",
      "          accuracy                           0.74      1353\n",
      "         macro avg       0.72      0.71      0.71      1353\n",
      "      weighted avg       0.73      0.74      0.73      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[188  16  44  71]\n",
      " [  6 329  49   5]\n",
      " [ 18  20 344  12]\n",
      " [ 68  12  37 134]]\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(n_neighbors=10)\n",
      "train time: 0.0020236968994140625fs\n",
      "test time:  0.10475349426269531fs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rob.DESKTOP-HBG5EOT\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:555: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.3946784922394678f\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.32      0.42      0.36       319\n",
      "     comp.graphics       0.49      0.48      0.48       389\n",
      "         sci.space       0.47      0.45      0.46       394\n",
      "talk.religion.misc       0.22      0.16      0.18       251\n",
      "\n",
      "          accuracy                           0.39      1353\n",
      "         macro avg       0.37      0.37      0.37      1353\n",
      "      weighted avg       0.39      0.39      0.39      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[133  47  81  58]\n",
      " [ 92 185  71  41]\n",
      " [101  78 177  38]\n",
      " [ 95  69  48  39]]\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier()\n",
      "train time: 0.6722333431243896fs\n",
      "test time:  0.04488062858581543fs\n",
      "accuracy:   0.7117516629711752f\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.58      0.62      0.60       319\n",
      "     comp.graphics       0.84      0.87      0.85       389\n",
      "         sci.space       0.72      0.84      0.77       394\n",
      "talk.religion.misc       0.65      0.39      0.48       251\n",
      "\n",
      "          accuracy                           0.71      1353\n",
      "         macro avg       0.70      0.68      0.68      1353\n",
      "      weighted avg       0.71      0.71      0.70      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[199  15  58  47]\n",
      " [ 12 337  40   0]\n",
      " [ 28  30 330   6]\n",
      " [103  18  33  97]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('RidgeClassifier', 0.7605321507760532, 0.033907175064086914, 0.0),\n",
       " ('Perceptron', 0.7191426459719142, 0.010387182235717773, 0.0),\n",
       " ('PassiveAggressiveClassifier',\n",
       "  0.7354028085735402,\n",
       "  0.01795172691345215,\n",
       "  0.000997781753540039),\n",
       " ('KNeighborsClassifier',\n",
       "  0.3946784922394678,\n",
       "  0.0020236968994140625,\n",
       "  0.10475349426269531),\n",
       " ('RandomForestClassifier',\n",
       "  0.7117516629711752,\n",
       "  0.6722333431243896,\n",
       "  0.04488062858581543)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "for clf, name in (\n",
    "    (RidgeClassifier(tol=1e-2, solver=\"sag\"), \"Ridge Classifier\"),\n",
    "    (Perceptron(max_iter=50), \"Perceptron\"),\n",
    "    (PassiveAggressiveClassifier(max_iter=50), \"Passive-Aggressive\"),\n",
    "    (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "    (RandomForestClassifier(), \"Random forest\"),\n",
    "):\n",
    "    print(\"=\" * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf, ))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(dual=False, tol=0.001)\n",
      "train time: 0.015963315963745117fs\n",
      "test time:  0.0009984970092773438fs\n",
      "accuracy:   0.7590539541759054f\n",
      "dimensionality: 1500\n",
      "density: 1.0\n",
      "top 10 keywords per class:\n",
      "alt.atheism: nanci islamic islam motto risk atheist bobby atheists religion atheism\n",
      "comp.graphics: 3do sphere 68070 hi 42 file 3d image computer graphics\n",
      "sci.space: earth dc moon flight spacecraft nasa launch shuttle orbit space\n",
      "talk.religion.misc: ekr rosicrucian 666 children cult christ abortion fbi christians christian\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.70      0.58      0.63       319\n",
      "     comp.graphics       0.88      0.88      0.88       389\n",
      "         sci.space       0.74      0.91      0.81       394\n",
      "talk.religion.misc       0.66      0.56      0.60       251\n",
      "\n",
      "          accuracy                           0.76      1353\n",
      "         macro avg       0.74      0.73      0.73      1353\n",
      "      weighted avg       0.76      0.76      0.75      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[185  12  54  68]\n",
      " [  6 344  37   2]\n",
      " [ 14  20 358   2]\n",
      " [ 61  14  36 140]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(max_iter=50)\n",
      "train time: 0.012964487075805664fs\n",
      "test time:  0.0fs\n",
      "accuracy:   0.7516629711751663f\n",
      "dimensionality: 1500\n",
      "density: 0.9103333333333333\n",
      "top 10 keywords per class:\n",
      "alt.atheism: hitler nanci atheists motto religion texts atheist risk bobby atheism\n",
      "comp.graphics: video sphere file 3do image 3d 68070 42 computer graphics\n",
      "sci.space: flight speculation star centaur nasa liftoff launch shuttle orbit space\n",
      "talk.religion.misc: authority 666 terrorist cult abortion christian fbi josephus christians ekr\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.67      0.59      0.63       319\n",
      "     comp.graphics       0.88      0.88      0.88       389\n",
      "         sci.space       0.75      0.89      0.81       394\n",
      "talk.religion.misc       0.63      0.55      0.59       251\n",
      "\n",
      "          accuracy                           0.75      1353\n",
      "         macro avg       0.73      0.73      0.73      1353\n",
      "      weighted avg       0.75      0.75      0.75      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[187  13  50  69]\n",
      " [  9 341  36   3]\n",
      " [ 18  17 352   7]\n",
      " [ 64  16  34 137]]\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(dual=False, penalty='l1', tol=0.001)\n",
      "train time: 0.02694106101989746fs\n",
      "test time:  0.0fs\n",
      "accuracy:   0.7450110864745011f\n",
      "dimensionality: 1500\n",
      "density: 0.18433333333333332\n",
      "top 10 keywords per class:\n",
      "alt.atheism: believing risk religion deletions motto atheism atheist atheists tek bobby\n",
      "comp.graphics: 42 computer sphere hi pov 68070 file image 3d graphics\n",
      "sci.space: orion lunar rocket dc shuttle spacecraft flight launch orbit space\n",
      "talk.religion.misc: blood josephus rosicrucian witness children hare 666 fbi cult christ\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.68      0.57      0.62       319\n",
      "     comp.graphics       0.88      0.87      0.87       389\n",
      "         sci.space       0.72      0.89      0.79       394\n",
      "talk.religion.misc       0.65      0.55      0.59       251\n",
      "\n",
      "          accuracy                           0.75      1353\n",
      "         macro avg       0.73      0.72      0.72      1353\n",
      "      weighted avg       0.74      0.75      0.74      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[181  10  59  69]\n",
      " [  7 338  41   3]\n",
      " [ 20  19 352   3]\n",
      " [ 57  17  40 137]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(max_iter=50, penalty='l1')\n",
      "train time: 0.03290843963623047fs\n",
      "test time:  0.0010018348693847656fs\n",
      "accuracy:   0.7597930524759793f\n",
      "dimensionality: 1500\n",
      "density: 0.38466666666666666\n",
      "top 10 keywords per class:\n",
      "alt.atheism: weak maddi risk atheism atheists posters deletions atheist believing bobby\n",
      "comp.graphics: video pov sphere 42 image 3d bitmap file computer graphics\n",
      "sci.space: nasm flight star orion spacecraft shuttle launch dc orbit space\n",
      "talk.religion.misc: christians rosicrucian christ xian authority ekr 666 josephus cult fbi\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.69      0.59      0.63       319\n",
      "     comp.graphics       0.88      0.88      0.88       389\n",
      "         sci.space       0.76      0.89      0.82       394\n",
      "talk.religion.misc       0.64      0.58      0.61       251\n",
      "\n",
      "          accuracy                           0.76      1353\n",
      "         macro avg       0.74      0.74      0.74      1353\n",
      "      weighted avg       0.76      0.76      0.75      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[187  11  49  72]\n",
      " [  8 344  33   4]\n",
      " [ 15  20 352   7]\n",
      " [ 60  14  32 145]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('RidgeClassifier', 0.7605321507760532, 0.033907175064086914, 0.0),\n",
       " ('Perceptron', 0.7191426459719142, 0.010387182235717773, 0.0),\n",
       " ('PassiveAggressiveClassifier',\n",
       "  0.7354028085735402,\n",
       "  0.01795172691345215,\n",
       "  0.000997781753540039),\n",
       " ('KNeighborsClassifier',\n",
       "  0.3946784922394678,\n",
       "  0.0020236968994140625,\n",
       "  0.10475349426269531),\n",
       " ('RandomForestClassifier',\n",
       "  0.7117516629711752,\n",
       "  0.6722333431243896,\n",
       "  0.04488062858581543),\n",
       " ('LinearSVC l2',\n",
       "  0.7590539541759054,\n",
       "  0.015963315963745117,\n",
       "  0.0009984970092773438),\n",
       " ('SGDClassifier l2', 0.7516629711751663, 0.012964487075805664, 0.0),\n",
       " ('LinearSVC l1', 0.7450110864745011, 0.02694106101989746, 0.0),\n",
       " ('SGDClassifier l1',\n",
       "  0.7597930524759793,\n",
       "  0.03290843963623047,\n",
       "  0.0010018348693847656)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(penalty=penalty, dual=False, tol=1e-3), apptext = penalty))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=0.0001, max_iter=50, penalty=penalty), apptext=penalty))\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(max_iter=50, penalty='elasticnet')\n",
      "train time: 0.03194308280944824fs\n",
      "test time:  0.0009999275207519531fs\n",
      "accuracy:   0.7568366592756837f\n",
      "dimensionality: 1500\n",
      "density: 0.7593333333333333\n",
      "top 10 keywords per class:\n",
      "alt.atheism: indonesian nanci atheists texts motto religion atheist risk atheism bobby\n",
      "comp.graphics: video sphere 3do file image 68070 3d 42 computer graphics\n",
      "sci.space: nasm rocket star nasa centaur liftoff launch shuttle orbit space\n",
      "talk.religion.misc: hare abortion christian 666 terrorist fbi cult josephus ekr christians\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.68      0.56      0.62       319\n",
      "     comp.graphics       0.91      0.88      0.89       389\n",
      "         sci.space       0.74      0.90      0.81       394\n",
      "talk.religion.misc       0.64      0.59      0.61       251\n",
      "\n",
      "          accuracy                           0.76      1353\n",
      "         macro avg       0.74      0.73      0.73      1353\n",
      "      weighted avg       0.75      0.76      0.75      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[180  12  53  74]\n",
      " [  7 341  37   4]\n",
      " [ 19  13 355   7]\n",
      " [ 59   9  35 148]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SGD with Elastic Net penalty\n",
    "print(\"=\" * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(\n",
    "    benchmark(SGDClassifier(alpha=0.0001, max_iter=50, penalty=\"elasticnet\"), apptext='EN')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid()\n",
      "train time: 0.0039577484130859375fs\n",
      "test time:  0.0010297298431396484fs\n",
      "accuracy:   0.7354028085735402f\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.64      0.53      0.58       319\n",
      "     comp.graphics       0.90      0.83      0.86       389\n",
      "         sci.space       0.72      0.90      0.80       394\n",
      "talk.religion.misc       0.62      0.60      0.61       251\n",
      "\n",
      "          accuracy                           0.74      1353\n",
      "         macro avg       0.72      0.71      0.71      1353\n",
      "      weighted avg       0.74      0.74      0.73      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[168  11  58  82]\n",
      " [ 15 322  47   5]\n",
      " [ 18  18 354   4]\n",
      " [ 63   5  32 151]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train NearestCentroid without threshold\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "print(\"=\" * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01)\n",
      "train time: 0.0019941329956054688fs\n",
      "test time:  0.000997304916381836fs\n",
      "accuracy:   0.7730968218773097f\n",
      "dimensionality: 1500\n",
      "density: 1.0\n",
      "top 10 keywords per class:\n",
      "alt.atheism: believe atheists said atheism religion say think people don god\n",
      "comp.graphics: help need hi looking program image file files thanks graphics\n",
      "sci.space: people shuttle don earth think moon launch orbit nasa space\n",
      "talk.religion.misc: say did bible think christians don christian people jesus god\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.69      0.66      0.67       319\n",
      "     comp.graphics       0.91      0.89      0.90       389\n",
      "         sci.space       0.77      0.91      0.83       394\n",
      "talk.religion.misc       0.66      0.52      0.58       251\n",
      "\n",
      "          accuracy                           0.77      1353\n",
      "         macro avg       0.76      0.75      0.75      1353\n",
      "      weighted avg       0.77      0.77      0.77      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[211   9  39  60]\n",
      " [  5 347  35   2]\n",
      " [ 15  16 357   6]\n",
      " [ 77  11  32 131]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01)\n",
      "train time: 0.0029935836791992188fs\n",
      "test time:  0.0009963512420654297fs\n",
      "accuracy:   0.7479674796747967f\n",
      "dimensionality: 1500\n",
      "density: 1.0\n",
      "top 10 keywords per class:\n",
      "alt.atheism: point ve believe religion said god say think people don\n",
      "comp.graphics: files file image help don program need use graphics thanks\n",
      "sci.space: years long orbit people earth use think nasa don space\n",
      "talk.religion.misc: point christian believe jesus did say think god don people\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.66      0.70      0.68       319\n",
      "     comp.graphics       0.74      0.93      0.83       389\n",
      "         sci.space       0.88      0.76      0.82       394\n",
      "talk.religion.misc       0.67      0.51      0.58       251\n",
      "\n",
      "          accuracy                           0.75      1353\n",
      "         macro avg       0.74      0.72      0.73      1353\n",
      "      weighted avg       0.75      0.75      0.74      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[222  33  13  51]\n",
      " [  6 363  18   2]\n",
      " [ 19  65 300  10]\n",
      " [ 88  28   8 127]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "ComplementNB(alpha=0.1)\n",
      "train time: 0.000997304916381836fs\n",
      "test time:  0.000997304916381836fs\n",
      "accuracy:   0.770140428677014f\n",
      "dimensionality: 1500\n",
      "density: 1.0\n",
      "top 10 keywords per class:\n",
      "alt.atheism: shatim bucaille apples wears marital categorizing theistic hindsight ingles cobb\n",
      "comp.graphics: sco raytracer clp genoa 68070 bitmap polygon vga tiff animation\n",
      "sci.space: jenks jacked miners hydrogen 483 docking martian advertising lunar spacecraft\n",
      "talk.religion.misc: joslin coerce oto gimme orthodoxy ordo kaflowitz passover lsd ye\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.62      0.69      0.65       319\n",
      "     comp.graphics       0.88      0.91      0.89       389\n",
      "         sci.space       0.87      0.82      0.85       394\n",
      "talk.religion.misc       0.65      0.57      0.61       251\n",
      "\n",
      "          accuracy                           0.77      1353\n",
      "         macro avg       0.75      0.75      0.75      1353\n",
      "      weighted avg       0.77      0.77      0.77      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[219  11  20  69]\n",
      " [ 20 354  14   1]\n",
      " [ 39  21 325   9]\n",
      " [ 76  17  14 144]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train sparse Naive Bayes classifiers\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=0.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=0.01)))\n",
    "results.append(benchmark(ComplementNB(alpha=0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LinearSVC(dual=False, penalty='l1',\n",
      "                                                     tol=0.001))),\n",
      "                ('classification', LinearSVC())])\n",
      "train time: 0.037868499755859375fs\n",
      "test time:  0.0010254383087158203fs\n",
      "accuracy:   0.7516629711751663f\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.69      0.56      0.62       319\n",
      "     comp.graphics       0.88      0.88      0.88       389\n",
      "         sci.space       0.73      0.90      0.81       394\n",
      "talk.religion.misc       0.65      0.56      0.60       251\n",
      "\n",
      "          accuracy                           0.75      1353\n",
      "         macro avg       0.74      0.73      0.73      1353\n",
      "      weighted avg       0.75      0.75      0.75      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[180  13  54  72]\n",
      " [  7 341  40   1]\n",
      " [ 15  21 355   3]\n",
      " [ 59  14  37 141]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "print(\"=\" * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(\n",
    "    benchmark(\n",
    "        Pipeline(\n",
    "            [\n",
    "                (\n",
    "                    \"feature_selection\",\n",
    "                    SelectFromModel(LinearSVC(penalty=\"l1\", dual=False, tol=1e-3)),\n",
    "                ),\n",
    "                (\"classification\", LinearSVC(penalty=\"l2\")),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add plots\n",
    "indices = np.arange(len(results))\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, 0.2, label=\"score\", color=\"navy\")\n",
    "plt.barh(indices + 0.3, training_time, 0.2, label=\"training time\", color=\"c\")\n",
    "plt.barh(indices + 0.6, test_time, 0.2, label=\"test time\", color=\"darkorange\")\n",
    "plt.yticks(())\n",
    "plt.legend(loc=\"best\")\n",
    "plt.subplots_adjust(left=0.25)\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.subplots_adjust(bottom=0.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-0.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one-off Kneighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1490</th>\n",
       "      <th>1491</th>\n",
       "      <th>1492</th>\n",
       "      <th>1493</th>\n",
       "      <th>1494</th>\n",
       "      <th>1495</th>\n",
       "      <th>1496</th>\n",
       "      <th>1497</th>\n",
       "      <th>1498</th>\n",
       "      <th>1499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2034.000000</td>\n",
       "      <td>2034.000000</td>\n",
       "      <td>2034.000000</td>\n",
       "      <td>2034.000000</td>\n",
       "      <td>2034.000000</td>\n",
       "      <td>2034.000000</td>\n",
       "      <td>2034.000000</td>\n",
       "      <td>2034.000000</td>\n",
       "      <td>2034.000000</td>\n",
       "      <td>2034.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2034.000000</td>\n",
       "      <td>2034.000000</td>\n",
       "      <td>2034.000000</td>\n",
       "      <td>2034.000000</td>\n",
       "      <td>2034.000000</td>\n",
       "      <td>2034.000000</td>\n",
       "      <td>2034.000000</td>\n",
       "      <td>2034.000000</td>\n",
       "      <td>2034.000000</td>\n",
       "      <td>2034.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>0.005437</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.014319</td>\n",
       "      <td>0.015627</td>\n",
       "      <td>0.008293</td>\n",
       "      <td>0.014780</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.011125</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>0.015390</td>\n",
       "      <td>0.021971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010199</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.012899</td>\n",
       "      <td>0.020612</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.005909</td>\n",
       "      <td>0.014158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.280698</td>\n",
       "      <td>0.201979</td>\n",
       "      <td>0.259718</td>\n",
       "      <td>0.184582</td>\n",
       "      <td>0.214754</td>\n",
       "      <td>0.304715</td>\n",
       "      <td>0.342437</td>\n",
       "      <td>0.214754</td>\n",
       "      <td>0.354277</td>\n",
       "      <td>0.364062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459983</td>\n",
       "      <td>0.317610</td>\n",
       "      <td>0.475821</td>\n",
       "      <td>0.620357</td>\n",
       "      <td>0.580812</td>\n",
       "      <td>0.348775</td>\n",
       "      <td>0.224543</td>\n",
       "      <td>0.582961</td>\n",
       "      <td>0.164637</td>\n",
       "      <td>0.362648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0            1            2            3            4     \\\n",
       "count  2034.000000  2034.000000  2034.000000  2034.000000  2034.000000   \n",
       "mean      0.001471     0.002999     0.000376     0.002156     0.000599   \n",
       "std       0.014319     0.015627     0.008293     0.014780     0.010190   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.280698     0.201979     0.259718     0.184582     0.214754   \n",
       "\n",
       "              5            6            7            8            9     ...  \\\n",
       "count  2034.000000  2034.000000  2034.000000  2034.000000  2034.000000  ...   \n",
       "mean      0.002771     0.000514     0.000599     0.001565     0.003045  ...   \n",
       "std       0.017775     0.011125     0.010190     0.015390     0.021971  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       0.304715     0.342437     0.214754     0.354277     0.364062  ...   \n",
       "\n",
       "              1490         1491         1492         1493         1494  \\\n",
       "count  2034.000000  2034.000000  2034.000000  2034.000000  2034.000000   \n",
       "mean      0.000226     0.000275     0.001091     0.000942     0.000302   \n",
       "std       0.010199     0.008000     0.016695     0.021118     0.012899   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.459983     0.317610     0.475821     0.620357     0.580812   \n",
       "\n",
       "              1495         1496         1497         1498         1499  \n",
       "count  2034.000000  2034.000000  2034.000000  2034.000000  2034.000000  \n",
       "mean      0.003947     0.005437     0.000844     0.000273     0.000964  \n",
       "std       0.020612     0.021339     0.021277     0.005909     0.014158  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       0.348775     0.224543     0.582961     0.164637     0.362648  \n",
       "\n",
       "[8 rows x 1500 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train.todense()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.32      0.42      0.36       319\n",
      "     comp.graphics       0.49      0.48      0.48       389\n",
      "         sci.space       0.47      0.45      0.46       394\n",
      "talk.religion.misc       0.22      0.16      0.18       251\n",
      "\n",
      "          accuracy                           0.39      1353\n",
      "         macro avg       0.37      0.37      0.37      1353\n",
      "      weighted avg       0.39      0.39      0.39      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[133  47  81  58]\n",
      " [ 92 185  71  41]\n",
      " [101  78 177  38]\n",
      " [ 95  69  48  39]]\n"
     ]
    }
   ],
   "source": [
    "#skeleton for one-off run\n",
    "clf = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "\n",
    "\n",
    "if hasattr(clf, \"coef_\"):\n",
    "    print(f\"dimensionality: {clf.coef_.shape[1]}\" )\n",
    "    print(f\"density: {density(clf.coef_)}\"  )\n",
    "\n",
    "    if opts.print_top10 and feature_names is not None:\n",
    "        print(\"top 10 keywords per class:\")\n",
    "        for i, label in enumerate(target_names):\n",
    "            top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "            print(f\"{label}: {' '.join(feature_names[top10])}\".strip() )\n",
    "\n",
    "if opts.print_report:\n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred, target_names=target_names))\n",
    "\n",
    "if opts.print_cm:\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "result = ( \"desc\", score, \"train_time\", \"test_time\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, ..., False,  True, False])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = clf.predict(X_train)\n",
    "pred2 == y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 10,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    593\n",
       "1    584\n",
       "0    480\n",
       "3    377\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    421\n",
       "1    379\n",
       "2    377\n",
       "3    176\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_s = pd.Series(pred)\n",
    "pred_s.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one-off Kmeans clustering\n",
    "clustering = un-labeled data = unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KMeans(n_clusters=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#skeleton for one-off run\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.07574390e-03, 2.82512826e-03, 2.13833867e-03, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.97840507e-03],\n",
       "       [1.57110575e-03, 3.14473586e-03, 0.00000000e+00, ...,\n",
       "        1.20034446e-03, 0.00000000e+00, 9.95317325e-05],\n",
       "       [0.00000000e+00, 2.52804116e-03, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 2.38174330e-03, 1.53577359e-04]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1431\n",
       "1     358\n",
       "3     233\n",
       "0      12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_s = pd.Series(clf.labels_)\n",
    "lab_s.value_counts(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, ..., 1, 3, 2])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_pos</th>\n",
       "      <th>pred_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>act_pos</th>\n",
       "      <td>TP</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_neg</th>\n",
       "      <td>FP</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred_pos pred_neg\n",
       "act_pos       TP       FN\n",
       "act_neg       FP       TN"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([('TP', 'FN'),('FP', 'TN')], columns = ['pred_pos', 'pred_neg'], index=['act_pos', 'act_neg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## interpreting multi-class confusion matrix\n",
    "[helps a bit but wording is confusing](https://www.analyticsvidhya.com/blog/2021/06/confusion-matrix-for-multi-class-classification/)\n",
    "\n",
    "|population = P+N|pred_pos|pred_neg|\n",
    "| --- | --- | --- |\n",
    "|act_pos|TP|FN|\n",
    "|act_neg|FP|TN|\n",
    "\n",
    "- TP = \n",
    "    - prediction was correct - the diagonal of CF\n",
    "    - CF\\[0,0\\]\n",
    "- FN = \n",
    "    - predicted something other than actual \n",
    "    - for row 0 the sum of all values in columns\\[1:\\] for this row\n",
    "    - The sum of valuesiun the row except the TP value\n",
    "\n",
    "- FP = \n",
    "    - TBD \n",
    "    - for column 0 the sum of all values in rows\\[1:\\] \n",
    "    - The sum of values of corresponding column except the TP value.\n",
    "\n",
    "- TN = \n",
    "    - we poredicted it wasn't this, and it isn't - \n",
    "    - The sum of everything that isn't in the row or column for the class\n",
    "\n",
    "performance:\n",
    "- Accuracy (ACC) = (TP + TN)/(P + N) = (true_pos+true_neg) / (act_pos+act_neg)\n",
    "- precision= TP/PP = true_postive / sum(pred_pos)\n",
    "- recall/sensitivity = TP/P  = true_positive / sum(act_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notes from a bad site with lots of tricksy pop-up ads\n",
    "- accuracy\n",
    "    - range 0 to 1\n",
    "    - calc = (TP+TN) divided by 'total number of a dataset P+N' (what does that mean? everything)\n",
    "    - balanced accruacy average of proprotion of corrects of each class individually \n",
    "    \n",
    "### notes from a less bad site\n",
    "https://medium.com/analytics-vidhya/confusion-matrix-accuracy-precision-recall-f1-score-ade299cf63cd\n",
    "same author as the link above?\n",
    "- accuracy = $ \\large \\frac{(TN+TP)}{(TN+TP+FP+FN)} $\n",
    "- precision = $ \\large \\frac{TP}{(TP+FP)} $\n",
    "- recall = $ \\large\\frac{TP}{(TP+FN)} $\n",
    "-  F1 $ = 2 \\times \\large \\frac{(precision \\times recall)}{(precision + recall)} $ - is this being used in place of the accuracy score because accuracy == bad\n",
    "\n",
    "### notes from BMC site\n",
    "https://www.bmc.com/blogs/confusion-precision-recall/\n",
    "- Precision = TP/(TP + FP)\n",
    "- Recall = TP/(TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.50      0.01      0.02       480\n",
      "     comp.graphics       0.94      0.58      0.72       584\n",
      "         sci.space       0.40      0.97      0.57       593\n",
      "talk.religion.misc       0.46      0.28      0.35       377\n",
      "\n",
      "          accuracy                           0.50      2034\n",
      "         macro avg       0.58      0.46      0.41      2034\n",
      "      weighted avg       0.59      0.50      0.44      2034\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5039331366764995"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CF = pd.DataFrame(metrics.confusion_matrix(y_train, clf.labels_))\n",
    "#https://www.analyticsvidhya.com/blog/2021/06/confusion-matrix-for-multi-class-classification/\n",
    "\n",
    "TP = CF.loc[0,0] # TP are on the diag\n",
    "FN = CF.loc[0, 1:] #all columns not on the dia\n",
    "#report to reproduce\n",
    "print(metrics.classification_report(y_train, clf.labels_, target_names=target_names))\n",
    "metrics.accuracy_score(y_train, clf.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the row(predictions)\n",
      "   0  1    2    3\n",
      "0  6  1  347  126\n",
      "the col(actuals)\n",
      "   0\n",
      "0  6\n",
      "1  0\n",
      "2  0\n",
      "3  6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>337</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>262</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3\n",
       "0  6    1  347  126\n",
       "1  0  337  247    0\n",
       "2  0   18  575    0\n",
       "3  6    2  262  107"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('the row(predictions)', CF.loc[0].to_frame().T, sep='\\n')#the row (predictions)\n",
    "\n",
    "print('the col(actuals)',CF.loc[:, 0].to_frame(), sep='\\n') #the column (actuals)\n",
    "CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP            256.250000\n",
      "FP            252.250000\n",
      "FN            252.250000\n",
      "TN           1273.250000\n",
      "accuracy        0.751967\n",
      "precision       0.575596\n",
      "recall          0.460755\n",
      "f1              0.414723\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alt.atheism</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>1548.0</td>\n",
       "      <td>0.764012</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics</th>\n",
       "      <td>337.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>0.868240</td>\n",
       "      <td>0.941341</td>\n",
       "      <td>0.577055</td>\n",
       "      <td>0.715499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.space</th>\n",
       "      <td>575.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>0.570305</td>\n",
       "      <td>0.401817</td>\n",
       "      <td>0.969646</td>\n",
       "      <td>0.568182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk.religion.misc</th>\n",
       "      <td>107.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>0.805310</td>\n",
       "      <td>0.459227</td>\n",
       "      <td>0.283820</td>\n",
       "      <td>0.350820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       TP     FP     FN      TN  accuracy  precision  \\\n",
       "alt.atheism           6.0    6.0  474.0  1548.0  0.764012   0.500000   \n",
       "comp.graphics       337.0   21.0  247.0  1429.0  0.868240   0.941341   \n",
       "sci.space           575.0  856.0   18.0   585.0  0.570305   0.401817   \n",
       "talk.religion.misc  107.0  126.0  270.0  1531.0  0.805310   0.459227   \n",
       "\n",
       "                      recall        f1  \n",
       "alt.atheism         0.012500  0.024390  \n",
       "comp.graphics       0.577055  0.715499  \n",
       "sci.space           0.969646  0.568182  \n",
       "talk.religion.misc  0.283820  0.350820  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does the metrics module computes TP, FP, FN, TN for all classes and take the average\n",
    "#accuracy is reported as f1 so I do not think it is using the commonly reported calc\n",
    "def get_confusion(CF, i):\n",
    "    \"\"\"\n",
    "    demonstration of taking apart the multi-variate confusion matrix to get teh 2x2\n",
    "    and also calculate the common metrics for each classification group\n",
    "    CF: a multivariate confusiotn matrix (DataFrame from ndarray)\n",
    "    i: the variable index for which to show the traditional 2x2 confusion matrix\n",
    "    \n",
    "    computed accuracy score matches with the 'macro avg' computed by sklearn.metrics.classification_report\n",
    "    \"\"\"\n",
    "    TP = CF.loc[i,i]\n",
    "    FN = CF.loc[i].sum() - TP\n",
    "    FP = CF.loc[:, i].sum() - TP\n",
    "    TN = CF.values.sum() - CF.loc[i].sum() - CF.loc[:,i].sum() + TP # or CF.values.sum() - FN - FP\n",
    "    #since TP is subtracted twice (as part of the row and as part of the column - need to add it back once to get the right total)\n",
    "    cfout =pd.DataFrame([[TP,FN],[FP,TN]], columns = ['pred_pos', 'pred_neg'], index=['act_pos', 'act_neg'])\n",
    "    #act_neg = FP + TN\n",
    "    accuracy = (TP+TN)/(TP+TN+FP+FN) # (TP+TN)/(TP+FN)\n",
    "    precision = TP / (TP+FP) #yes, but no? #TP/pred_pos #pred_pos = TP + FP # \n",
    "    recall =  TP/(TP+FN) #TP/act_pos #act_pos = TP + FN#\n",
    "    f1 = 2*(precision * recall) / (precision+recall)\n",
    "    #print((i), f\"TP is {TP}; FP is {FP}; FN is {FN}; TN is {TN}\" )\n",
    "    cols = ['TP', 'FP', 'FN', 'TN', 'accuracy', 'precision', 'recall', 'f1']\n",
    "    res = pd.Series([TP, FP, FN, TN, accuracy, precision, recall, f1 ], index=cols)\n",
    "    return res\n",
    "\n",
    "#for i in CF.index:\n",
    "#    get_confusion(CF, i)\n",
    "\n",
    "#get_confusion(CF, 0)\n",
    "\n",
    "allgroups = pd.Series(CF.index).apply(lambda x: get_confusion(CF, x))\n",
    "print(allgroups.mean())\n",
    "allgroups.index = target_names #replace numeric index with category names\n",
    "allgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accuracy score vs actual real labels\n",
    "from documentation: \n",
    "\n",
    "> The reported averages include macro average (averaging the unweighted\n",
    "mean per label), weighted average (averaging the support-weighted mean\n",
    "per label), and sample average (only for multilabel classification).\n",
    "Micro average (averaging the total true positives, false negatives and\n",
    "false positives) is only shown for multi-label or multi-class\n",
    "with a subset of classes, because it corresponds to accuracy otherwise.\n",
    "See also `precision_recall_fscore_support` for more details\n",
    "on averages.\n",
    ">\n",
    ">Note that in binary classification, recall of the positive class\n",
    "is also known as \"sensitivity\"; recall of the negative class is\n",
    "\"specificity\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt.atheism': {'precision': 0.3159144893111639,\n",
       "  'recall': 0.4169278996865204,\n",
       "  'f1-score': 0.35945945945945945,\n",
       "  'support': 319},\n",
       " 'comp.graphics': {'precision': 0.48812664907651715,\n",
       "  'recall': 0.4755784061696658,\n",
       "  'f1-score': 0.48177083333333326,\n",
       "  'support': 389},\n",
       " 'sci.space': {'precision': 0.46949602122015915,\n",
       "  'recall': 0.44923857868020306,\n",
       "  'f1-score': 0.4591439688715953,\n",
       "  'support': 394},\n",
       " 'talk.religion.misc': {'precision': 0.2215909090909091,\n",
       "  'recall': 0.1553784860557769,\n",
       "  'f1-score': 0.18266978922716626,\n",
       "  'support': 251},\n",
       " 'accuracy': 0.3946784922394678,\n",
       " 'macro avg': {'precision': 0.37378201717468734,\n",
       "  'recall': 0.37428084264804157,\n",
       "  'f1-score': 0.3707610127228886,\n",
       "  'support': 1353},\n",
       " 'weighted avg': {'precision': 0.39265243098565217,\n",
       "  'recall': 0.3946784922394678,\n",
       "  'f1-score': 0.3908568089916197,\n",
       "  'support': 1353}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.classification_report(y_test, pred, target_names=target_names, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc score is 0.5039331366764995\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.32      0.42      0.36       319\n",
      "     comp.graphics       0.49      0.48      0.48       389\n",
      "         sci.space       0.47      0.45      0.46       394\n",
      "talk.religion.misc       0.22      0.16      0.18       251\n",
      "\n",
      "          accuracy                           0.39      1353\n",
      "         macro avg       0.37      0.37      0.37      1353\n",
      "      weighted avg       0.39      0.39      0.39      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[133  47  81  58]\n",
      " [ 92 185  71  41]\n",
      " [101  78 177  38]\n",
      " [ 95  69  48  39]]\n"
     ]
    }
   ],
   "source": [
    "score = metrics.accuracy_score(y_train, clf.labels_)\n",
    "print(f\"acc score is {score}\")\n",
    "\n",
    "if hasattr(clf, \"coef_\"):\n",
    "    print(f\"dimensionality: {clf.coef_.shape[1]}\" )\n",
    "    print(f\"density: {density(clf.coef_)}\"  )\n",
    "\n",
    "    if opts.print_top10 and feature_names is not None:\n",
    "        print(\"top 10 keywords per class:\")\n",
    "        for i, label in enumerate(target_names):\n",
    "            top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "            print(f\"{label}: {' '.join(feature_names[top10])}\".strip() )\n",
    "\n",
    "if opts.print_report:\n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred, target_names=target_names))\n",
    "\n",
    "if opts.print_cm:\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "result = ( \"desc\", score, \"train_time\", \"test_time\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.01      0.01      0.01       319\n",
      "     comp.graphics       0.00      0.00      0.00       389\n",
      "         sci.space       0.36      0.97      0.52       394\n",
      "talk.religion.misc       0.00      0.00      0.00       251\n",
      "\n",
      "          accuracy                           0.28      1353\n",
      "         macro avg       0.09      0.24      0.13      1353\n",
      "      weighted avg       0.11      0.28      0.15      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[  2   0 310   7]\n",
      " [261   0 128   0]\n",
      " [ 12   0 382   0]\n",
      " [  3   0 248   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rob.DESKTOP-HBG5EOT\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "score = metrics.accuracy_score(y_test, pred)\n",
    "\n",
    "\n",
    "if hasattr(clf, \"coef_\"):\n",
    "    print(f\"dimensionality: {clf.coef_.shape[1]}\" )\n",
    "    print(f\"density: {density(clf.coef_)}\"  )\n",
    "\n",
    "    if opts.print_top10 and feature_names is not None:\n",
    "        print(\"top 10 keywords per class:\")\n",
    "        for i, label in enumerate(target_names):\n",
    "            top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "            print(f\"{label}: {' '.join(feature_names[top10])}\".strip() )\n",
    "\n",
    "if opts.print_report:\n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred, target_names=target_names))\n",
    "\n",
    "if opts.print_cm:\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "result = ( \"desc\", score, \"train_time\", \"test_time\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
